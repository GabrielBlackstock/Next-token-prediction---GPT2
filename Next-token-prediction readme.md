# Next Token Prediction Using GPT-2

## Overview
This project demonstrates the use of the GPT-2 model, a pre-trained transformer model by OpenAI, to perform next token prediction. 
The application extends the functionality to generate complete sentences or phrases by continually predicting the next token until reaching a full stop, question mark, or exclamation point.



